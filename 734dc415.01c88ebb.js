(window.webpackJsonp=window.webpackJsonp||[]).push([[17],{100:function(e,t,n){"use strict";n.d(t,"a",(function(){return d})),n.d(t,"b",(function(){return u}));var a=n(0),o=n.n(a);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function i(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function l(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?i(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):i(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function c(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},r=Object.keys(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}var s=o.a.createContext({}),p=function(e){var t=o.a.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):l(l({},t),e)),n},d=function(e){var t=p(e.components);return o.a.createElement(s.Provider,{value:t},e.children)},b={inlineCode:"code",wrapper:function(e){var t=e.children;return o.a.createElement(o.a.Fragment,{},t)}},m=o.a.forwardRef((function(e,t){var n=e.components,a=e.mdxType,r=e.originalType,i=e.parentName,s=c(e,["components","mdxType","originalType","parentName"]),d=p(n),m=a,u=d["".concat(i,".").concat(m)]||d[m]||b[m]||r;return n?o.a.createElement(u,l(l({ref:t},s),{},{components:n})):o.a.createElement(u,l({ref:t},s))}));function u(e,t){var n=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var r=n.length,i=new Array(r);i[0]=m;var l={};for(var c in t)hasOwnProperty.call(t,c)&&(l[c]=t[c]);l.originalType=e,l.mdxType="string"==typeof e?e:a,i[1]=l;for(var s=2;s<r;s++)i[s]=n[s];return o.a.createElement.apply(null,i)}return o.a.createElement.apply(null,n)}m.displayName="MDXCreateElement"},73:function(e,t,n){"use strict";n.r(t),n.d(t,"frontMatter",(function(){return i})),n.d(t,"metadata",(function(){return l})),n.d(t,"rightToc",(function(){return c})),n.d(t,"default",(function(){return p}));var a=n(2),o=n(6),r=(n(0),n(100)),i={id:"docker_install_simple",title:"Docker Default Installation Guide",sidebar_label:"Docker Simple"},l={unversionedId:"deploy/docker_install_simple",id:"deploy/docker_install_simple",isDocsHomePage:!1,title:"Docker Default Installation Guide",description:"The default Docker installation can bring up 2 nfdump collectors and the Netsage Pipeline (Importer plus logstash pipeline). It can work with one sflow and/or one netflow and/or any number of tstat data sources.",source:"@site/docs/deploy/docker_install_simple.md",slug:"/deploy/docker_install_simple",permalink:"/netsage-pipeline/docs/next/deploy/docker_install_simple",editUrl:"https://github.com/netsage-project/netsage-pipeline/edit/master/website/docs/deploy/docker_install_simple.md",version:"current",sidebar_label:"Docker Simple",sidebar:"Pipeline",previous:{title:"NetSage Flow Processing Pipeline Installation Guide",permalink:"/netsage-pipeline/docs/next/deploy/bare_metal_install"},next:{title:"Docker Advanced Installation Guide",permalink:"/netsage-pipeline/docs/next/deploy/docker_install_advanced"}},c=[{value:"To begin",id:"to-begin",children:[]},{value:"Docker-compose.override.yml",id:"docker-composeoverrideyml",children:[]},{value:"Pipeline Version",id:"pipeline-version",children:[]},{value:"Environment File",id:"environment-file",children:[]},{value:"Running the Collectors",id:"running-the-collectors",children:[]},{value:"Running the Pipeline",id:"running-the-pipeline",children:[]},{value:"Data sources",id:"data-sources",children:[]},{value:"Upgrading",id:"upgrading",children:[]}],s={rightToc:c};function p(e){var t=e.components,n=Object(o.a)(e,["components"]);return Object(r.b)("wrapper",Object(a.a)({},s,n,{components:t,mdxType:"MDXLayout"}),Object(r.b)("p",null,"The default Docker installation can bring up 2 nfdump collectors and the Netsage Pipeline (Importer plus logstash pipeline). It can work with one sflow and/or one netflow and/or any number of tstat data sources."),Object(r.b)("h3",{id:"to-begin"},"To begin"),Object(r.b)("p",null,"Install Docker/compose and clone this project (netsage-pipeline) from github."),Object(r.b)("p",null,"There are four things that need to be done to make the nfdump sflow and netflow collectors (sfcapd and nfcapd processes that listen for incoming flow data) work with the Netsage Pipeline."),Object(r.b)("ul",null,Object(r.b)("li",{parentName:"ul"},"an ENV value needs to be set that sets the sensor name."),Object(r.b)("li",{parentName:"ul"},"a unique data output path should be set."),Object(r.b)("li",{parentName:"ul"},"importer needs to be updated to be aware of the filepath and the sensor name.")),Object(r.b)("h3",{id:"docker-composeoverrideyml"},"Docker-compose.override.yml"),Object(r.b)("p",null,"The default pattern for running the Pipeline is defined in the docker-compose.override_example.yml. Copy this to docker-compose.override.yml. By default we bring up a single netflow collector and a single sflow collector. For most people this is more than enough. You may wish to delete collectors you're not using."),Object(r.b)("pre",null,Object(r.b)("code",Object(a.a)({parentName:"pre"},{className:"language-sh"}),"cp docker-compose.override_example.yml docker-compose.override.yml\n")),Object(r.b)("p",null,"If you're sticking to the default you don't need to make any changes to the docker-compose.override_example.yml"),Object(r.b)("div",{className:"admonition admonition-note alert alert--secondary"},Object(r.b)("div",Object(a.a)({parentName:"div"},{className:"admonition-heading"}),Object(r.b)("h5",{parentName:"div"},Object(r.b)("span",Object(a.a)({parentName:"h5"},{className:"admonition-icon"}),Object(r.b)("svg",Object(a.a)({parentName:"span"},{xmlns:"http://www.w3.org/2000/svg",width:"14",height:"16",viewBox:"0 0 14 16"}),Object(r.b)("path",Object(a.a)({parentName:"svg"},{fillRule:"evenodd",d:"M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"})))),"note")),Object(r.b)("div",Object(a.a)({parentName:"div"},{className:"admonition-content"}),Object(r.b)("p",{parentName:"div"},"You may need to remove all the comments in the override file as they may conflict with the parsing done by docker-compose"))),Object(r.b)("div",{className:"admonition admonition-note alert alert--secondary"},Object(r.b)("div",Object(a.a)({parentName:"div"},{className:"admonition-heading"}),Object(r.b)("h5",{parentName:"div"},Object(r.b)("span",Object(a.a)({parentName:"h5"},{className:"admonition-icon"}),Object(r.b)("svg",Object(a.a)({parentName:"span"},{xmlns:"http://www.w3.org/2000/svg",width:"14",height:"16",viewBox:"0 0 14 16"}),Object(r.b)("path",Object(a.a)({parentName:"svg"},{fillRule:"evenodd",d:"M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"})))),"note")),Object(r.b)("div",Object(a.a)({parentName:"div"},{className:"admonition-content"}),Object(r.b)("p",{parentName:"div"},"If you are only interested in netflow OR sflow data, you should remove the section for the collector that is not used."))),Object(r.b)("h3",{id:"pipeline-version"},"Pipeline Version"),Object(r.b)("p",null,"Once you've created the docker-compose.override.xml and finished adjusting it for any customizations, then you're ready to select your version."),Object(r.b)("ul",null,Object(r.b)("li",{parentName:"ul"},"Select Release version",Object(r.b)("ul",{parentName:"li"},Object(r.b)("li",{parentName:"ul"},Object(r.b)("inlineCode",{parentName:"li"},"git fetch; git checkout <tag name>"),' replace "tag name" with v1.2.5 or the version you intend to use.'),Object(r.b)("li",{parentName:"ul"},"Then also please select the version you wish to use by running ",Object(r.b)("inlineCode",{parentName:"li"},"./scripts/docker_select_version.sh"))))),Object(r.b)("h3",{id:"environment-file"},"Environment File"),Object(r.b)("p",null,Object(r.b)("p",{parentName:"p"},"Please copy ",Object(r.b)("inlineCode",{parentName:"p"},"env.example")," to ",Object(r.b)("inlineCode",{parentName:"p"},".env"),"  "),Object(r.b)("pre",{parentName:"p"},Object(r.b)("code",Object(a.a)({parentName:"pre"},{className:"language-sh"}),"cp env.example .env \n")),Object(r.b)("p",{parentName:"p"},"Then edit the .env file and look for the sensor name settings"),Object(r.b)("pre",{parentName:"p"},Object(r.b)("code",Object(a.a)({parentName:"pre"},{className:"language-sh"}),"sflowSensorName= sflow sensor name\nnetflowSensorName= netflow ensor name\n")),Object(r.b)("p",{parentName:"p"},"Simply change the names to unique identifiers and you're good to go.  ???? Do these need quotes ????"),Object(r.b)("div",Object(a.a)({parentName:"p"},{className:"admonition admonition-note alert alert--secondary"}),Object(r.b)("div",Object(a.a)({parentName:"div"},{className:"admonition-heading"}),Object(r.b)("h5",{parentName:"div"},Object(r.b)("span",Object(a.a)({parentName:"h5"},{className:"admonition-icon"}),Object(r.b)("svg",Object(a.a)({parentName:"span"},{xmlns:"http://www.w3.org/2000/svg",width:"14",height:"16",viewBox:"0 0 14 16"}),Object(r.b)("path",Object(a.a)({parentName:"svg"},{fillRule:"evenodd",d:"M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"})))),"note")),Object(r.b)("div",Object(a.a)({parentName:"div"},{className:"admonition-content"}),Object(r.b)("p",{parentName:"div"},'These names uniquely identify the source of the data. Choose names that are meaningful and unique.\nFor example, your your sensor names might be "RNDNet Sflow" and "RNDNet Netflow" or "rtr.one.rndnet.edu" and "rtr.two.nrdnet.edu".'))),Object(r.b)("ul",{parentName:"p"},Object(r.b)("li",{parentName:"ul"},"If you don't send a sensor name it'll use the default docker hostname which changes each time you run the pipeline (not good!)."),Object(r.b)("li",{parentName:"ul"},"If you have only one collector, comment out the line for the one you are not using."),Object(r.b)("li",{parentName:"ul"},'If you have more than one of the same type of collector, see the "Docker Advanced" documentation.'),Object(r.b)("li",{parentName:"ul"},"If you're not using a netflow or an sflow collector (you are getting only tstat data), then simply disregard the env settings.")),Object(r.b)("p",{parentName:"p"},"Other settings of note in this file includes the following. You will not normally need to change these, but be aware."),Object(r.b)("p",{parentName:"p"},Object(r.b)("em",{parentName:"p"},"rabbit_output_host"),": this defines where the final data will land.  ??? Need more info about what to set this for internal or external rabbit hosts???"),Object(r.b)("p",{parentName:"p"},Object(r.b)("em",{parentName:"p"},"rabbit_output_key"),": the name of the queue Netsage uses as the last stop before insertion into elasticsearch"),Object(r.b)("p",{parentName:"p"},"The Logstash Aggregation Filter settings are exposed in case you wish to use different values.\n(See comments in the ","*","-aggregation.conf file.) This config stitches together long-lasting flows that are seen in multiple nfcapd files, matching by the 5-tuple (source and destination IPs, ports, and protocol) plus sensor name. "),Object(r.b)("p",{parentName:"p"},Object(r.b)("em",{parentName:"p"},"Aggregation_maps_path"),": the name of the file to which logstash will write in-progress aggregation data when logstash shuts down. When logstash starts up again, it will read this file in and resume aggregating. The filename is configurable, but /data/ is required.  "),Object(r.b)("p",{parentName:"p"},Object(r.b)("em",{parentName:"p"},"Inactivity_timeout"),": If more than inactivity_timeout seconds have passed between the 'start' of this event and the 'start'\nof the LAST matching event, OR if no matching flow has coming in for inactivity_timeout seconds\non the clock, assume the flow has ended."),Object(r.b)("p",{parentName:"p"},":::Note\nNfcapd files are typically written every 5 minutes. Use 630 sec = 10.5 min for 5-min files,  960 sec = 16 min for if you have 15-min files.  (For 5-min files, this allows one 5 min gap or period during which the no. of bits transferred don't meet the cutoff)\n:::"),Object(r.b)("p",{parentName:"p"},Object(r.b)("em",{parentName:"p"},"max_flow_timeout"),": If a flow is still aggregating when this timeout is reached, arbitrarily cut it off and start a new flow.  The default is 24 hours.")),Object(r.b)("h3",{id:"running-the-collectors"},"Running the Collectors"),Object(r.b)("p",null,"After selecting the version to run, you can start the two collectors by running the following line"),Object(r.b)("pre",null,Object(r.b)("code",Object(a.a)({parentName:"pre"},{className:"language-sh"}),"docker-compose up -d sflow-collector netflow-collector\n")),Object(r.b)("p",null,"By default the container comes up and will write data (as nfcapd files) to ",Object(r.b)("inlineCode",{parentName:"p"},"/data/input_data/")," . Each collector is namespaced by its type so sflow collector will write data to ",Object(r.b)("inlineCode",{parentName:"p"},"/data/input_data/sflow/")," and the netflow collector will write data to ",Object(r.b)("inlineCode",{parentName:"p"},"/data/input_data/netflow/"),"."),Object(r.b)("p",null,"By default, the sflow collector will listen to udp traffic on localhost:9998, while the netflow collector will listen on port 9999."),Object(r.b)("p",null,"These are set in the docker-compose.override.yml file."),Object(r.b)("h3",{id:"running-the-pipeline"},"Running the Pipeline"),Object(r.b)("p",null,Object(r.b)("p",{parentName:"p"},"Start up the pipeline using:"),Object(r.b)("pre",{parentName:"p"},Object(r.b)("code",Object(a.a)({parentName:"pre"},{className:"language-sh"}),"docker-compose up -d\n")),Object(r.b)("p",{parentName:"p"},"You can check the logs for each of the container by running"),Object(r.b)("pre",{parentName:"p"},Object(r.b)("code",Object(a.a)({parentName:"pre"},{className:"language-sh"}),"docker-compose logs\n")),Object(r.b)("p",{parentName:"p"},"Shut down the pipeline using:"),Object(r.b)("pre",{parentName:"p"},Object(r.b)("code",Object(a.a)({parentName:"pre"},{className:"language-sh"}),"docker-compose down\n"))),Object(r.b)("h2",{id:"data-sources"},"Data sources"),Object(r.b)("p",null,"The data processing pipeline needs data to ingest in order to do anything, of course. There are two types of data that can be consumed."),Object(r.b)("p",null,"sflow or netflow\ntstat\nAt least one of these must be set up on a sensor to provide the incoming flow data."),Object(r.b)("p",null,"Sflow and netflow data should be sent to ports on the pipeline host where nfcapd and/or sfcapd are ready to receive it."),Object(r.b)("p",null,"Tstat data should be sent directly to the logstash input RabbitMQ queue (the same one that the Importer writes to, if it is used). From there, the data will be processed the same as sflow/netflow data."),Object(r.b)("h2",{id:"upgrading"},"Upgrading"),Object(r.b)("p",null,Object(r.b)("h3",{parentName:"p"},"Update Source Code"),Object(r.b)("p",{parentName:"p"},"If your only changes are the version you selected simply reset and discard your changes."),Object(r.b)("pre",{parentName:"p"},Object(r.b)("code",Object(a.a)({parentName:"pre"},{className:"language-sh"}),"git reset --hard\n")),Object(r.b)("p",{parentName:"p"},"Update the git repo. Likely this won't change anything but it's always a good practice to have the latest version. You will need to do at least a git fetch in order to see the latest tags."),Object(r.b)("pre",{parentName:"p"},Object(r.b)("code",Object(a.a)({parentName:"pre"},{className:"language-sh"}),"git pull origin master\n")),Object(r.b)("h3",{parentName:"p"},"Collectors"),Object(r.b)("p",{parentName:"p"},"Since the collectors live outside of version control. Please check the docker-compose.override_example.yml and see if there any changes you need to bring in."),Object(r.b)("p",{parentName:"p"},"Likely the only change of note might be the docker version."),Object(r.b)("pre",{parentName:"p"},Object(r.b)("code",Object(a.a)({parentName:"pre"},{className:"language-yaml"}),'version: "3.7"\n')),Object(r.b)("h3",{parentName:"p"},"Select Release Version"),Object(r.b)("ol",{parentName:"p"},Object(r.b)("li",{parentName:"ol"},"git checkout <tag_value> (ie. v1.2.6, v1.2.7 etc)"),Object(r.b)("li",{parentName:"ol"},Object(r.b)("inlineCode",{parentName:"li"},"./scripts/docker_select_version.sh")," select the same version as the tag you checked out.")),Object(r.b)("h3",{parentName:"p"},"Update docker containers"),Object(r.b)("p",{parentName:"p"},"This applies for both development and release"),Object(r.b)("pre",{parentName:"p"},Object(r.b)("code",Object(a.a)({parentName:"pre"},{}),"docker-compose pull\n"))))}p.isMDXComponent=!0}}]);