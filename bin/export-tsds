#!/usr/bin/perl

use strict;
use warnings;

use GRNOC::Config;

use MongoDB;
use Getopt::Long;
use JSON::XS;

use Data::Dumper;

my $BATCH_SIZE = 100;

my $end = time;
my $start = $end - 86400 * 7; # 1 day

warn "start: " . Dumper $start;
warn "end: " . Dumper $end;

my $USAGE = "$0 --to <email>";

my $email_to = "";

#GetOptions("to=s" => \$email_to) or die $USAGE;

#if (! $email_to){
#    die $USAGE;
#}

my $config = GRNOC::Config->new(config_file => "/etc/grnoc/tsds/services/config.xml",
				force_array => 0);

my $host = $config->get('/config/mongo/@host');
my $port = $config->get('/config/mongo/@port');
my $user = $config->get('/config/mongo/root');

my $mongo = MongoDB::MongoClient->new(
    host     => "$host:$port",
    username => $user->{'user'},
    password => $user->{'password'}
    );

my $flow_db = $mongo->get_database('flow');

my $json = JSON::XS->new();

my $measurements_count = $flow_db->get_collection('measurements')->count();
my $data_count = $flow_db->get_collection('data')->count();
my $storage_stats = $flow_db->run_command( { dbStats => 1 } );

my $string = "Information for 'flow' database (before):\n\n";
$string .= "Num Measurement Docs -> $measurements_count\n";
$string .= "Num Data Docs        -> $data_count\n";
$string .= "Sizeof Data bytes    -> $storage_stats->{'dataSize'}\n";
$string .= "Sizeof Storage bytes -> $storage_stats->{'storageSize'}\n";

warn "$string\n";

$string = "";

my $meas_col = $flow_db->get_collection('measurements');
my $data_col = $flow_db->get_collection('data');

my $max_count = 0;
my $max_size = 0;
my $filter = {
    #start => { '$gt' => $start, '$lt' => $end },
    #end => { '$lt' => $end } # NOTE: measurement->end seems to be undef in many (all?) cases
    };
#warn "filter " . Dumper $filter;
my $data = $data_col->find( $filter );
my $batch = [];
my $meas_count = 0;
my $total_count = 0;

# We start with the values and then retrieve the metadata as this
# is more straightforward

my $measurement;
my $prev_id = "none";
while (my $val_doc = $data->next) {
    my $row = {};
    #print "val doc: " . Dumper $doc;
    my $id = $val_doc->{'identifier'};
    #warn "identifier: $id";
    #my $data_res = $data_col->find({ identifier => $id })->count;
    my $measurements = $meas_col->find(
    { 
        identifier => $id,
    })->limit(1);
    #if ( $data_res > $max_count ) {
#		$max_count = $data_res;
#	}
    #warn "count: $data_res";
    my $count = 0;

    # dumbly cache/reuse measurement if it has the same identifier as the previous record
    if ( $id ne $prev_id ) {
        while (my $meas_doc = $measurements->next) {
            $measurement = $meas_doc;
            $count++;
            $meas_count++;
            warn " NUM MEAS IS NOT 1!! $count " if $count != 1;
            last;
        }

    }
    #warn "rrecords" . Dumper $records;
    #foreach my $record ( @$records ) {
    $row = $val_doc;
    #warn "record " . Dumper $record;
    $row->{'meta'} = $measurement;
    #warn "before changes " . Dumper $row;
    $row = _prepare_data( $row );
    #warn "after changes " . Dumper $row;
    #warn "row size: $size";
    #die;
    #warn "data_res: " . Dumper $data_res;
    if ( $size > $max_size ) {
        $max_size = $size;

    }
    _output_archive( $row );
    $prev_id = $id;
    #}
    #push @$batch, $row;
    #warn "row " . Dumper $row;
    #if ( @$batch >= $BATCH_SIZE ) {
    #    _output_archive( $batch );
    #    $batch = [];
    #}
    $total_count++;
}

warn "measurement records: $meas_count";
warn "data records: $total_count";

# output remaining messages
if ( @$batch > 0 ) {
    _output_archive( $batch );
}


warn "max count: $max_count; max size: $max_size";
#warn "measurements " . Dumper $measurements;

$measurements_count = $flow_db->get_collection('measurements')->count();
$data_count = $flow_db->get_collection('data')->count();
$storage_stats = $flow_db->run_command( { dbStats => 1 } );

$string = "Information for 'flow' database (after):\n\n";
$string .= "Num Measurement Docs -> $measurements_count\n";
$string .= "Num Data Docs        -> $data_count\n";
$string .= "Sizeof Data bytes    -> $storage_stats->{'dataSize'}\n";
$string .= "Sizeof Storage bytes -> $storage_stats->{'storageSize'}\n";

warn "$string\n";

$string = "";

sub _prepare_data {
	my $row = shift;
	$row = _cleanup_extra_fields( $row );
    delete $row->{'meta'}->{'start'};
    delete $row->{'meta'}->{'end'};
    if ( not exists $row->{'meta'}->{'sensor_id'} ) {
        $row->{'meta'}->{'sensor_id'} = 'unknown';
    }
    if ( not exists $row->{'meta'}->{'flow_type'} ) {
        $row->{'meta'}->{'flow_type'} = 'unknown';
    }
    $row->{'type'} = 'flow';
	return $row;
}

# recursively clean up extra fields
# delete _id field
sub _cleanup_extra_fields {
    my $obj = shift;
    foreach my $key ( keys %$obj ) {
        my $val = $obj->{$key};
        #warn "null value; key: $key " if not defined $val;
        $val = '' if not defined $val;
        if ( ref($val) eq 'HASH' ) { 
            # recurse
            $val = _cleanup_extra_fields( $val );
        } elsif ( ref($val) eq 'ARRAY' ) {
            for(my $i=0; $i<@$val;$i++) {
                $val->[$i] = _cleanup_extra_fields( $val->[$i] );
            }
        } else {
            delete $obj->{'_id'};
            delete $obj->{'identifier'};
            delete $obj->{'updated_start'};
            delete $obj->{'updated_end'};
        }
    }

    return $obj;
}

sub _output_archive {
    my $data = shift;
    my $output = $json->encode( $data );
    print "$output\n";

}

